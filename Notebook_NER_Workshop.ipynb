{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "99faa0ec",
      "metadata": {
        "id": "99faa0ec"
      },
      "source": [
        "# AI for Research: Customizing spaCy's Entity Recognition Models (Virtual)\n",
        "\n",
        "**Welcome to this interactive notebook!**  \n",
        "In this workshop, we'll walk through how Named Entity Recognition (NER) works, test pre-trained models, and learn how to customize them for research tasks, particularly useful in domains like hate speech detection, misinformation research, or media studies.\n",
        "\n",
        "\n",
        "### Prerequisites\n",
        "- Basic knowledge of Python\n",
        "- No prior experience with NER or spaCy required"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This workshop was held on November 12, 2025, as part of the Research Computing and Data Services' **AI for Research** workshop series at Northwestern University, led by [Miriam Schirmer](https://miriamschirmer.github.io/).*"
      ],
      "metadata": {
        "id": "cpNOcd7Rbn4s"
      },
      "id": "cpNOcd7Rbn4s"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. Introduction to Named Entity Recognition**"
      ],
      "metadata": {
        "id": "CUHzsnB-dYu6"
      },
      "id": "CUHzsnB-dYu6"
    },
    {
      "cell_type": "markdown",
      "id": "f9684b7f",
      "metadata": {
        "id": "f9684b7f"
      },
      "source": [
        "### What is Named Entity Recognition?\n",
        "\n",
        "**NER** is a technique in Natural Language Processing (NLP) that identifies and classifies real-world entities in text.\n",
        "\n",
        "This sentence for example, has the following entities:\n",
        "\n",
        "*Dr. Jane Smith from the World Health Organization gave a talk in Geneva on July 15, 2021, about COVID-19.*\n",
        "\n",
        "- **PERSON** ‚Äì e.g., \"Dr. Jane Smith\"\n",
        "- **ORG** ‚Äì e.g., \"World Health Organization\"\n",
        "- **GPE** ‚Äì Geopolitical Entities, e.g., \"Geneva\"\n",
        "- **DATE** ‚Äì e.g., \"July 15, 2021\"\n",
        "- **Others** ‚Äì PRODUCT, EVENT, LAW, NORP (Nationalities or religious or political groups), etc.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Why is NER Important?\n",
        "\n",
        "NER helps:\n",
        "- Structure very raw and unformatted text, e.g., to get an overview of common terms used\n",
        "- Enable information extraction from social media, news, legal texts, etc.\n",
        "- Use it as an additional step for other NLP tasks (e.g., look at who is targeted when training a model to detect hate speech)\n"
      ],
      "metadata": {
        "id": "4cBvCQCDd0aY"
      },
      "id": "4cBvCQCDd0aY"
    },
    {
      "cell_type": "markdown",
      "id": "4054ada5",
      "metadata": {
        "id": "4054ada5"
      },
      "source": [
        "### Prep: Import relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d20c3be6",
      "metadata": {
        "id": "d20c3be6"
      },
      "outputs": [],
      "source": [
        "# Import spaCy itself to build our pipeline: spaCy is the core NLP library we'll use.\n",
        "# spaCy provides pre-built pipelines for tasks like NER (and many more!).\n",
        "import spacy\n",
        "\n",
        "# Import \"Matcher\", which lets us define custom patterns\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Import \"EntityRuler\", which allows us to add custom rules for entities\n",
        "from spacy.pipeline import EntityRuler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80570ee8",
      "metadata": {
        "id": "80570ee8"
      },
      "source": [
        "### **Intro Example**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We‚Äôll start by loading **spaCy‚Äôs small English model**, called `en_core_web_sm`.\n",
        "\n",
        "- **`en_core_web_sm`** stands for *English (core) web-trained small model*.  \n",
        "  It includes the basic components of spaCy‚Äôs NLP pipeline: a tokenizer, part-of-speech tagger, dependency parser, and named entity recognizer.  \n",
        "- The **small model** is lightweight and fast, which makes it ideal for demos and teaching.  \n",
        "- For more accuracy (but slower performance), you can use:\n",
        "  - `en_core_web_md` ‚Üí *medium* model (includes word vectors)\n",
        "  - `en_core_web_lg` ‚Üí *large* model (best accuracy, higher memory use)\n",
        "- You can also train your own model or use models for other languages."
      ],
      "metadata": {
        "id": "8MfceWo2-2cF"
      },
      "id": "8MfceWo2-2cF"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8e9840e2",
      "metadata": {
        "id": "8e9840e2"
      },
      "outputs": [],
      "source": [
        "# Load spaCy's small English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "843c8407",
      "metadata": {
        "id": "843c8407"
      },
      "outputs": [],
      "source": [
        "# A simple text example\n",
        "text = \"Dr. Jane Smith from the World Health Organization gave a talk in Geneva on July 15, 2021, about COVID-19.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2c5685d7",
      "metadata": {
        "id": "2c5685d7"
      },
      "outputs": [],
      "source": [
        "# Run the NLP pipeline on the text\n",
        "doc = nlp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "750e2beb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "750e2beb",
        "outputId": "f1ffc5b1-8b2c-407d-9a20-9bd93ade98f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities Found:\n",
            "- Jane Smith (PERSON) [Start: 4, End: 14]\n",
            "- the World Health Organization (ORG) [Start: 20, End: 49]\n",
            "- Geneva (GPE) [Start: 65, End: 71]\n",
            "- July 15, 2021 (DATE) [Start: 75, End: 88]\n",
            "- COVID-19 (ORG) [Start: 96, End: 104]\n"
          ]
        }
      ],
      "source": [
        "# Print entities detected by the model, including start and end character\n",
        "print(\"Entities Found:\")\n",
        "for ent in doc.ents:\n",
        "    print(f\"- {ent.text} ({ent.label_}) [Start: {ent.start_char}, End: {ent.end_char}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize this:"
      ],
      "metadata": {
        "id": "tkN-AvqI3_lF"
      },
      "id": "tkN-AvqI3_lF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize entities in the text\n",
        "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "oA3kc8BP4DTX",
        "outputId": "37620ca1-4910-45f8-a55e-b2b918a0abb2"
      },
      "id": "oA3kc8BP4DTX",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Dr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jane Smith\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " from \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the World Health Organization\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " gave a talk in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Geneva\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    July 15, 2021\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", about \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    COVID-19\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7953c99c",
      "metadata": {
        "id": "7953c99c"
      },
      "source": [
        "###**Excersise**: Use your own example and run this!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A simple text example (enter a sentence between the quotation marks)\n",
        "new_text = \"\""
      ],
      "metadata": {
        "id": "foiE4KSoenCs"
      },
      "id": "foiE4KSoenCs",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the NLP pipeline on the text\n",
        "new_doc ="
      ],
      "metadata": {
        "id": "tFImWKtrfHLj"
      },
      "id": "tFImWKtrfHLj",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print entities detected by the model, including start and end character\n",
        "print(\"Entities Found:\")\n",
        "for ent in new_doc.ents:\n",
        "    print(f\"- {ent.text} ({ent.label_}) [Start: {ent.start_char}, End: {ent.end_char}]\")"
      ],
      "metadata": {
        "id": "y2yO_MoKfOuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd5e97f-2a27-48fb-8eb1-30bd43ff93bb"
      },
      "id": "y2yO_MoKfOuN",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities Found:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8948a9c5",
      "metadata": {
        "id": "8948a9c5"
      },
      "source": [
        "## **2. Applying NER to Real-World Data: Incel Forum Posts**\n",
        "\n",
        "Now that we've seen a basic example, let‚Äôs test how spaCy‚Äôs off-the-shelf NER performs on **incel forum posts**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80852124",
      "metadata": {
        "id": "80852124"
      },
      "source": [
        "### Background: What are \"incel\" forums?\n",
        "\n",
        "The term **incel** stands for \"involuntary celibate.\"  \n",
        "It refers to online communities where people discuss frustrations about dating and relationships, often expressing **hateful language toward women** and **misogynistic ideologies**.  \n",
        "\n",
        "Why are we using this data?\n",
        "- They use **slang and community-specific terms** that are different from everyday language but also contain **clear references to people, groups, and institutions**\n",
        "- They provide examples of **messy, real-world text** where standard NLP models may struggle.\n",
        "- They are publicly available data often used in research on online communities.\n",
        "\n",
        "This is especially relevant for **hate speech detection research**, where:\n",
        "- Extracting entities helps identify targeted individuals or groups.\n",
        "- We may want to track mentions of public figures, communities, or ideologies.\n",
        "\n",
        "‚ö†Ô∏è In this workshop, we use incel forum text **only as an example** to show how NER works on social science data.  \n",
        "Our focus is on the **method (NER)**, not on the community or its views.\n",
        "\n",
        "üö® Content warning: Incel terminology often contains misogynistic expressions and may reference sexual or gender-based violence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a153e5b2",
      "metadata": {
        "id": "a153e5b2"
      },
      "source": [
        "### üìÇ Step 1: Load Dataset and Inspect `text` Column\n",
        "\n",
        "We have a dataset (CSV file) of incel posts with a column called `text`. This column contains the raw text of each post made in a forum.\n",
        "\n",
        "We'll load the data, inspect a few entries, and then apply spaCy's NER model to extract named entities.\n",
        "\n",
        "üîç This mimics a typical hate speech or social media dataset structure. Note that this is **raw, unprocessed data**. It‚Äôs intentionally left messy to illustrate the kinds of challenges you might face when applying NER, and to show how to clean and prepare your data for this task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "b3ebb611",
      "metadata": {
        "id": "b3ebb611"
      },
      "outputs": [],
      "source": [
        "# Import the pandas library for working with tables (dataframes)\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with the raw URL (click \"Raw\" on the GitHub file page to copy it)\n",
        "url = \"https://raw.githubusercontent.com/MiriamSchirmer/Intro-to-NER/refs/heads/main/incel_comments.csv\"\n",
        "\n",
        "# Read CSV directly from GitHub\n",
        "# Load your dataset into a pandas DataFrame\n",
        "# A DataFrame is like a table (rows = observations, columns = variables)\n",
        "\n",
        "df = pd.read_csv(url)\n"
      ],
      "metadata": {
        "id": "OA75MtXdgMr0"
      },
      "id": "OA75MtXdgMr0",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "10ae3298",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "10ae3298",
        "outputId": "f501d644-8f35-4740-9477-a25a1b3c35e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                     filename  \\\n",
              "0                                                         1-158-bluepillers.242071#page-1.tsv   \n",
              "1                                                                1100-guests.42211#page-1.tsv   \n",
              "2                                 30-hours-sleep-deprived-and-i-take-my-zma.147784#page-1.tsv   \n",
              "3       51-blackcel-ricecel-r-short-mod-with-his-taller-8-10-coalburner-wife.67975#page-1.tsv   \n",
              "4  a-lot-of-my-high-effort-threads-get-ignored-but-my-lower-effort-ones-dont.80016#page-1.tsv   \n",
              "\n",
              "   index  \\\n",
              "0    8.0   \n",
              "1    5.0   \n",
              "2    1.0   \n",
              "3   42.0   \n",
              "4    4.0   \n",
              "\n",
              "                                                                                                                                                                                                                                            text  \\\n",
              "0  I lurked here and on the subreddit for a long time before joining. A lot of the time I'm too high inhib to actually log in and post anything, so I just browse without logging in. But, the more incel perspectives we hear from, the better.   \n",
              "1                                                                                                                                                                                         It hasn't been 1000+ in a few day. New fake news link?   \n",
              "2                                                                                                                                  i wagecuck full time (12 hours shift) and i try to dont sleep to have more time to LDAR pls free @ kingturtle   \n",
              "3                                                                                                                          Demetrious Johnson is 5'3 but one of the top fighters in UFC. He was like the longest reigning champion or something.   \n",
              "4                                                                                                                                 I guess bad timming OP. It depents who is online to see it , what's the curent mood of members online, etc etc   \n",
              "\n",
              "                                                                                       entities  \n",
              "0                                                                                            []  \n",
              "1                                                    [('1000+', 'DATE'), ('a few day', 'DATE')]  \n",
              "2                                                      [('12 hours', 'TIME'), ('LDAR', 'NORP')]  \n",
              "3  [('Demetrious Johnson', 'PERSON'), (\"5'3\", 'CARDINAL'), ('one', 'CARDINAL'), ('UFC', 'GPE')]  \n",
              "4                                                                                            []  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1168da3-7a20-4837-a40c-d25566a106c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1-158-bluepillers.242071#page-1.tsv</td>\n",
              "      <td>8.0</td>\n",
              "      <td>I lurked here and on the subreddit for a long time before joining. A lot of the time I'm too high inhib to actually log in and post anything, so I just browse without logging in. But, the more incel perspectives we hear from, the better.</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1100-guests.42211#page-1.tsv</td>\n",
              "      <td>5.0</td>\n",
              "      <td>It hasn't been 1000+ in a few day. New fake news link?</td>\n",
              "      <td>[('1000+', 'DATE'), ('a few day', 'DATE')]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30-hours-sleep-deprived-and-i-take-my-zma.147784#page-1.tsv</td>\n",
              "      <td>1.0</td>\n",
              "      <td>i wagecuck full time (12 hours shift) and i try to dont sleep to have more time to LDAR pls free @ kingturtle</td>\n",
              "      <td>[('12 hours', 'TIME'), ('LDAR', 'NORP')]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>51-blackcel-ricecel-r-short-mod-with-his-taller-8-10-coalburner-wife.67975#page-1.tsv</td>\n",
              "      <td>42.0</td>\n",
              "      <td>Demetrious Johnson is 5'3 but one of the top fighters in UFC. He was like the longest reigning champion or something.</td>\n",
              "      <td>[('Demetrious Johnson', 'PERSON'), (\"5'3\", 'CARDINAL'), ('one', 'CARDINAL'), ('UFC', 'GPE')]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a-lot-of-my-high-effort-threads-get-ignored-but-my-lower-effort-ones-dont.80016#page-1.tsv</td>\n",
              "      <td>4.0</td>\n",
              "      <td>I guess bad timming OP. It depents who is online to see it , what's the curent mood of members online, etc etc</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1168da3-7a20-4837-a40c-d25566a106c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f1168da3-7a20-4837-a40c-d25566a106c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f1168da3-7a20-4837-a40c-d25566a106c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-88df91cb-1955-4429-a131-510bcb47fbfa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88df91cb-1955-4429-a131-510bcb47fbfa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-88df91cb-1955-4429-a131-510bcb47fbfa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 108,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 106,\n        \"samples\": [\n          \"good-guys-dont-finish-last.411239#page-1.tsv\",\n          \"any-bladee-listeners-here.362368#page-1.tsv\",\n          \"a-lot-of-my-high-effort-threads-get-ignored-but-my-lower-effort-ones-dont.80016#page-1.tsv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.651836500742672,\n        \"min\": 1.0,\n        \"max\": 42.0,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          3.0,\n          10.0,\n          21.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 106,\n        \"samples\": [\n          \"good guys don't finish last, because it never even started for subhuman nice guys. its so over no matter how hard you try because its over\",\n          \"I've liked a few of his songs but some of them sounded like pure autotune garbage to me.\",\n          \"I guess bad timming OP. It depents who is online to see it , what's the curent mood of members online, etc etc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entities\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"[('night', 'TIME')]\",\n          \"[('first', 'ORDINAL'), ('the day', 'DATE')]\",\n          \"[('Covid', 'PERSON'), ('Coronavirus', 'ORG')]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "# Set pandas option to display the full content of the 'text' column\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Display the first 5 rows of the dataset to check what it looks like\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the shape of the DataFrame to see how many rows (first number) and columns (second number) we have\n",
        "print(\"Shape of the DataFrame:\")\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YEItp6jgeEB",
        "outputId": "44c7c045-7415-4440-a4d8-c5f6ad8ce0b5"
      },
      "id": "8YEItp6jgeEB",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the DataFrame:\n",
            "(108, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94970fdc",
      "metadata": {
        "id": "94970fdc"
      },
      "source": [
        "### üè∑ Step 2: Apply NER to the `text` Column\n",
        "\n",
        "Now we apply the NER pipeline to each post in the dataset.  \n",
        "We‚Äôll extract:\n",
        "- The full list of entities\n",
        "- Their labels (e.g., PERSON, ORG)\n",
        "- Their frequency in the dataset\n",
        "\n",
        "This helps us:\n",
        "- Spot key actors and targets in hate speech\n",
        "- Identify misclassifications (e.g., slang detected as ORG)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5c4fe9c",
      "metadata": {
        "id": "f5c4fe9c"
      },
      "source": [
        "Extract Named Entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "2b68a864",
      "metadata": {
        "id": "2b68a864"
      },
      "outputs": [],
      "source": [
        "# Define a function that takes in a piece of text and returns all named entities the model finds\n",
        "\n",
        "def extract_ents(text, nlp):\n",
        "    \"\"\"\n",
        "    Extract named entities from a given text using a spaCy pipeline.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text from which to extract entities.\n",
        "        nlp (spacy.language.Language): A loaded spaCy language model (e.g., spacy.load(\"en_core_web_sm\")).\n",
        "\n",
        "    Returns:\n",
        "        list of tuples: A list containing (entity_text, entity_label) pairs.\n",
        "    \"\"\"\n",
        "    # Process the text through the provided spaCy pipeline\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Collect each entity as a (text, label) pair\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "    return entities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "974f1f27",
      "metadata": {
        "id": "974f1f27"
      },
      "outputs": [],
      "source": [
        "# Define what our texts are\n",
        "texts = df['text']\n",
        "\n",
        "# Process all texts efficiently in batches (this saves time because we are not calling the model separately for each row)\n",
        "# You can adjust batch_size depending on text length\n",
        "docs = list(nlp.pipe(texts, batch_size=20)) # low-medium batch size because our posts are rather short\n",
        "\n",
        "# Extract entities for each processed doc\n",
        "df['entities'] = [[(ent.text, ent.label_) for ent in doc.ents] for doc in docs]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "de3cd830",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "de3cd830",
        "outputId": "59b59c62-68aa-49f6-9b98-10062dbc12a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                            text  \\\n",
              "72                                                                           Imagine lying on a hospital bed deathly ill and you turn your head and see this jfl   \n",
              "136                                         Ive written about this on shortcels. If you want proof about how bad manlets have it, just step outside and observe.   \n",
              "88                                                They mostly leech of their dads and see them as a betabuxx who pays for her shit till she rides cock carousels   \n",
              "95                                                                                              He looks constipated. Either that or he‚Äö√Ñ√¥s just doing the face.   \n",
              "107                                                                                                       I want to visit amusement park, haven't since I was 13   \n",
              "131  if she wants to be shorter than the bf, why'd she wear heels? foids have 0 iq as usual tbh heels also hurt the feet, why they wear them in the first place?   \n",
              "103                                                                                                          I don't know what that is supposed to mean anyways.   \n",
              "11                                        ama reddit. i was wrongfully imprisoned by yeti for three years. its so good to be back with my fellow kind strangers!   \n",
              "22                       Is it true that Norway is depressing (due to long winters and few hours of sun) and expensive but people can cope because they're rich?   \n",
              "51                                                                                             I dont even know how to find an escort...Im guessing ur a eurocel   \n",
              "23                                                                                                       It really pisses me off. They don‚Äö√Ñ√¥t really deserve it   \n",
              "84                                        There's enough biological difference that if dimorphism wasn't considered, then yes they would be a different species.   \n",
              "148                                  too much in a semester i'm fine with everything else but I hate OOP I can't design for shit the more math for me the better   \n",
              "100                       no i have the best personality that even existed ever in the history of humanity. toilets are just too dumb to see how wonderful it is   \n",
              "13                                                                      I've liked a few of his songs but some of them sounded like pure autotune garbage to me.   \n",
              "\n",
              "                                                    entities  \n",
              "72                                                        []  \n",
              "136                                                       []  \n",
              "88                                                        []  \n",
              "95                                                        []  \n",
              "107                                         [(13, CARDINAL)]  \n",
              "131                        [(0, CARDINAL), (first, ORDINAL)]  \n",
              "103                                                       []  \n",
              "11                                     [(three years, DATE)]  \n",
              "22   [(Norway, GPE), (winters, DATE), (and few hours, TIME)]  \n",
              "51                                               [(Im, ORG)]  \n",
              "23                                                        []  \n",
              "84                                                        []  \n",
              "148                                                       []  \n",
              "100                                                       []  \n",
              "13                                                        []  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c41799d8-86fa-4487-aef4-cb4d14642b0a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>Imagine lying on a hospital bed deathly ill and you turn your head and see this jfl</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>Ive written about this on shortcels. If you want proof about how bad manlets have it, just step outside and observe.</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>They mostly leech of their dads and see them as a betabuxx who pays for her shit till she rides cock carousels</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>He looks constipated. Either that or he‚Äö√Ñ√¥s just doing the face.</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>I want to visit amusement park, haven't since I was 13</td>\n",
              "      <td>[(13, CARDINAL)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>if she wants to be shorter than the bf, why'd she wear heels? foids have 0 iq as usual tbh heels also hurt the feet, why they wear them in the first place?</td>\n",
              "      <td>[(0, CARDINAL), (first, ORDINAL)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>I don't know what that is supposed to mean anyways.</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ama reddit. i was wrongfully imprisoned by yeti for three years. its so good to be back with my fellow kind strangers!</td>\n",
              "      <td>[(three years, DATE)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Is it true that Norway is depressing (due to long winters and few hours of sun) and expensive but people can cope because they're rich?</td>\n",
              "      <td>[(Norway, GPE), (winters, DATE), (and few hours, TIME)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>I dont even know how to find an escort...Im guessing ur a eurocel</td>\n",
              "      <td>[(Im, ORG)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>It really pisses me off. They don‚Äö√Ñ√¥t really deserve it</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>There's enough biological difference that if dimorphism wasn't considered, then yes they would be a different species.</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>too much in a semester i'm fine with everything else but I hate OOP I can't design for shit the more math for me the better</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>no i have the best personality that even existed ever in the history of humanity. toilets are just too dumb to see how wonderful it is</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>I've liked a few of his songs but some of them sounded like pure autotune garbage to me.</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c41799d8-86fa-4487-aef4-cb4d14642b0a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c41799d8-86fa-4487-aef4-cb4d14642b0a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c41799d8-86fa-4487-aef4-cb4d14642b0a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-23e0b74f-6ba0-41e9-aa0a-f4d123ab07a8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-23e0b74f-6ba0-41e9-aa0a-f4d123ab07a8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-23e0b74f-6ba0-41e9-aa0a-f4d123ab07a8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[['text', 'entities']]\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"I dont even know how to find an escort...Im guessing ur a eurocel\",\n          \"There's enough biological difference that if dimorphism wasn't considered, then yes they would be a different species.\",\n          \"Imagine lying on a hospital bed deathly ill and you turn your head and see this jfl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entities\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# Show 10 random rows with text and extracted entities\n",
        "df[['text', 'entities']].sample(15, random_state=38)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41858a95",
      "metadata": {
        "id": "41858a95"
      },
      "source": [
        "Count Most Common Entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "88e15bd3",
      "metadata": {
        "id": "88e15bd3"
      },
      "outputs": [],
      "source": [
        "# Import Counter, a helper tool that counts how often items appear in a list\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "de697605",
      "metadata": {
        "id": "de697605"
      },
      "outputs": [],
      "source": [
        "# Flatten (i.e., \"unzip\")the list of entities across all posts\n",
        "# - df['entities'] contains one list of entities per row\n",
        "# - We loop over each row and then each entity inside it\n",
        "all_entities = [ent for row in df['entities'] for ent in row]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "e5b4e80e",
      "metadata": {
        "id": "e5b4e80e"
      },
      "outputs": [],
      "source": [
        "# Count how often each (text, label) pair appears in the dataset\n",
        "entity_counter = Counter(all_entities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "43af9570",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43af9570",
        "outputId": "fe00996a-b6d3-433a-c850-4fc2c14ee9d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Frequent Named Entities:\n",
            "one (CARDINAL): 2\n",
            "today (DATE): 2\n",
            "100% (PERCENT): 2\n",
            "NSFW (ORG): 2\n",
            "0 (CARDINAL): 2\n",
            "first (ORDINAL): 2\n",
            "1000+ (DATE): 1\n",
            "a few day (DATE): 1\n",
            "12 hours (TIME): 1\n",
            "LDAR (NORP): 1\n",
            "Demetrious Johnson (PERSON): 1\n",
            "5'3 (CARDINAL): 1\n",
            "UFC (GPE): 1\n",
            "5% (PERCENT): 1\n",
            "Trucels (GPE): 1\n"
          ]
        }
      ],
      "source": [
        "# Print the 15 most frequent named entities\n",
        "print(\"Most Frequent Named Entities:\")\n",
        "for (text, label), count in entity_counter.most_common(15):\n",
        "    print(f\"{text} ({label}): {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapt this slightly to exclude the numbers (which we are not really interested in)."
      ],
      "metadata": {
        "id": "QGDm--HskQNc"
      },
      "id": "QGDm--HskQNc"
    },
    {
      "cell_type": "code",
      "source": [
        "exclude_labels = {\"CARDINAL\", \"ORDINAL\", \"WORK_OF_ART\", \"PERCENT\"}\n",
        "\n",
        "# Filter the entities to exclude those with labels in exclude_labels\n",
        "filtered_entities = [ent for ent in all_entities if ent[1] not in exclude_labels]\n",
        "\n",
        "# Count how often each (text, label) pair appears in the filtered list\n",
        "entity_counter = Counter(filtered_entities)\n",
        "\n",
        "# Print the 15 most frequent named entities from the filtered list\n",
        "print(\"Most Frequent Named Entities (excluding numbers):\")\n",
        "for (text, label), count in entity_counter.most_common(15):\n",
        "    print(f\"{text} ({label}): {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs4JY9sIkPPX",
        "outputId": "669ccf29-3224-4567-a355-09141c6fa3d5"
      },
      "id": "Qs4JY9sIkPPX",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Frequent Named Entities (excluding numbers):\n",
            "today (DATE): 2\n",
            "NSFW (ORG): 2\n",
            "1000+ (DATE): 1\n",
            "a few day (DATE): 1\n",
            "12 hours (TIME): 1\n",
            "LDAR (NORP): 1\n",
            "Demetrious Johnson (PERSON): 1\n",
            "UFC (GPE): 1\n",
            "Trucels (GPE): 1\n",
            "three years (DATE): 1\n",
            "Hollywood (GPE): 1\n",
            "my freshman year (DATE): 1\n",
            "Norway (GPE): 1\n",
            "winters (DATE): 1\n",
            "and few hours (TIME): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Discussion**: What works well, what does not work well? How can we improve this?"
      ],
      "metadata": {
        "id": "GLF1hEgti8UF"
      },
      "id": "GLF1hEgti8UF"
    },
    {
      "cell_type": "markdown",
      "id": "4fa8db14",
      "metadata": {
        "id": "4fa8db14"
      },
      "source": [
        "### What We Can Learn from the Entity Counts\n",
        "\n",
        "- Did the model mark any words as entities that **aren‚Äôt actually entities**?  \n",
        "- Are the **real people or names** we care about being tagged correctly?  \n",
        "- Are there **important words** that the model missed?\n",
        "\n",
        "These questions help us see what needs to be improved ‚Äî either by:\n",
        "- **Fixing** specific cases with simple rules (using the `EntityRuler`)\n",
        "- **Teaching** the model new examples through training\n",
        "\n",
        "Next, we‚Äôll look at how to **customize and improve** the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "617982af",
      "metadata": {
        "id": "617982af"
      },
      "source": [
        "## üß© Step 3: Why Customize NER?\n",
        "\n",
        "spaCy's default model doesn't recognize many **domain-specific concepts** in incel communities.\n",
        "\n",
        "Examples:\n",
        "- ‚ÄúChad‚Äù, ‚ÄúStacy‚Äù ‚Üí Often central figures, not recognized as people\n",
        "- ‚ÄúTinder‚Äù, ‚ÄúReddit‚Äù ‚Üí Should be detected as platforms\n",
        "- ‚ÄúRedpill‚Äù, ‚ÄúBlackpill‚Äù ‚Üí Ideologies\n",
        "- ‚Äúnormie‚Äù, ‚Äúfoid‚Äù  ‚Üí Community-specific terms\n",
        "\n",
        "Let‚Äôs start by using **spaCy‚Äôs Matcher** and **EntityRuler** to inject these into the pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef227cb5",
      "metadata": {
        "id": "ef227cb5"
      },
      "source": [
        "####üíª Customizing Option A: Rule-Based Matching with `Matcher`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "549d7690",
      "metadata": {
        "id": "549d7690"
      },
      "outputs": [],
      "source": [
        "# Create a Matcher object, which lets us define custom rules\n",
        "# It needs the vocabulary (nlp.vocab) from the spaCy model\n",
        "matcher = Matcher(nlp.vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "33039d61",
      "metadata": {
        "id": "33039d61"
      },
      "outputs": [],
      "source": [
        "# Define a simple pattern for the word \"chad\"\n",
        "# LOWER means: match the lowercase version of the token\n",
        "pattern_chad = [{\"LOWER\": \"chad\"}]\n",
        "\n",
        "# Define a pattern for the word \"stacy\"\n",
        "pattern_stacy = [{\"LOWER\": \"stacy\"}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "9c708d37",
      "metadata": {
        "id": "9c708d37"
      },
      "outputs": [],
      "source": [
        "# Add both patterns to the matcher under the same label \"INCEL_PERSON\"\n",
        "# The first argument (\"INSEL_PERSON\") is the name we give this rule\n",
        "# The second argument is a list of patterns we want to match\n",
        "matcher.add(\"INCEL_PERSON\", [pattern_chad, pattern_stacy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "0a14a9a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a14a9a1",
        "outputId": "97ff5961-eed9-421a-b02b-bea710c3d2ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total matches found: 2\n",
            "\n",
            "Most Frequent Matcher Hits:\n",
            "chad (INCEL_PERSON): 1\n",
            "Stacy (INCEL_PERSON): 1\n"
          ]
        }
      ],
      "source": [
        "# Store counts\n",
        "match_counter = Counter()\n",
        "total_matches = 0\n",
        "\n",
        "# Loop through your dataframe\n",
        "for doc in nlp.pipe(df[\"text\"], batch_size=50):\n",
        "    matches = matcher(doc)\n",
        "    total_matches += len(matches)\n",
        "\n",
        "    for match_id, start, end in matches:\n",
        "        label = nlp.vocab.strings[match_id]  # e.g. \"INCEL_PERSON\"\n",
        "        span_text = doc[start:end].text\n",
        "        match_counter[(span_text, label)] += 1\n",
        "\n",
        "# Summary\n",
        "print(f\"Total matches found: {total_matches}\\n\")\n",
        "\n",
        "print(\"Most Frequent Matcher Hits:\")\n",
        "for (text, label), count in match_counter.most_common():\n",
        "    print(f\"{text} ({label}): {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at an example that contains \"Stacy\":"
      ],
      "metadata": {
        "id": "_GBX6tnEnXwJ"
      },
      "id": "_GBX6tnEnXwJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Find a text entry that contains \"Stacy\"\n",
        "stacy_text = df[df['text'].str.contains('Stacy', case=False, na=False)].iloc[0]['text']\n",
        "\n",
        "# Print the text\n",
        "print(\"Example text containing 'Stacy':\")\n",
        "print(stacy_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4lvDwCKnLbs",
        "outputId": "8f95623b-3938-4e1b-f7ac-cf06c533bb59"
      },
      "id": "u4lvDwCKnLbs",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example text containing 'Stacy':\n",
            "Blonde Stacy - 7/10+ PSL, 6'0 or above, (almost) completely neurotypical Blonde Becky - 5/10+ PSL, 5'9\" or above, somewhat neuroatypical. Avoid dating apps and social media. Spoiler inb4 sub-8 copers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Excersise**: Choose a term you would like to add and run the the NER Matcher on our dataset!"
      ],
      "metadata": {
        "id": "HHIjm4UEwdne"
      },
      "id": "HHIjm4UEwdne"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your own pattern(s)\n",
        "\n",
        "new_pattern = [{\"LOWER\": \"\"}]\n",
        "matcher.add(\"\", [new_pattern])\n",
        "\n",
        "# ‚úèÔ∏è TODO: Replace the underscores above with your own term and label! Replace \"YOUR_LABEL_HERE\" with your label name."
      ],
      "metadata": {
        "id": "0STRMO7loNfG"
      },
      "id": "0STRMO7loNfG",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count how often we find your new pattern! (No adjustments needed.)\n",
        "\n",
        "# Store counts\n",
        "match_counter = Counter()\n",
        "total_matches = 0\n",
        "\n",
        "# Loop through your dataframe\n",
        "for doc in nlp.pipe(df[\"text\"], batch_size=50):\n",
        "    matches = matcher(doc)\n",
        "    total_matches += len(matches)\n",
        "\n",
        "    for match_id, start, end in matches:\n",
        "        label = nlp.vocab.strings[match_id]  # e.g. \"INCEL_PERSON\"\n",
        "        span_text = doc[start:end].text\n",
        "        match_counter[(span_text, label)] += 1\n",
        "\n",
        "# Summary\n",
        "print(f\"Total matches found: {total_matches}\\n\")\n",
        "\n",
        "print(\"Most Frequent Matcher Hits:\")\n",
        "for (text, label), count in match_counter.most_common():\n",
        "    print(f\"{text} ({label}): {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4crDq5NpBQ-",
        "outputId": "20cbdb9b-6ae6-460f-eb6d-adc0970fbb85"
      },
      "id": "I4crDq5NpBQ-",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total matches found: 2\n",
            "\n",
            "Most Frequent Matcher Hits:\n",
            "chad (INCEL_PERSON): 1\n",
            "Stacy (INCEL_PERSON): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85759833",
      "metadata": {
        "id": "85759833"
      },
      "source": [
        "###üíª Customizing Option B: Insert Custom Entities with `EntityRuler`\n",
        "\n",
        "The **EntityRuler** is similar to the Matcher, but with one key difference:\n",
        "\n",
        "- **Matcher**: Finds patterns in text but does not automatically turn them into \"entities\".  \n",
        "  ‚Üí We had to manually print the matches.  \n",
        "\n",
        "- **EntityRuler**: Lets us directly insert new *named entities* into spaCy‚Äôs pipeline.  \n",
        "  ‚Üí The matches will appear alongside other entities (like PERSON, ORG, DATE) when we run `doc.ents`.\n",
        "\n",
        "This makes the EntityRuler a better choice if we want our custom rules to behave just like the built-in NER model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reset the NLP Pipeline"
      ],
      "metadata": {
        "id": "O6ZYAMQLtPnO"
      },
      "id": "O6ZYAMQLtPnO"
    },
    {
      "cell_type": "code",
      "source": [
        "# Start fresh to avoid lingering patterns/rulers\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Remove any existing entity_ruler(s)\n",
        "for name in list(nlp.pipe_names):\n",
        "    if name.startswith(\"entity_ruler\"):\n",
        "        nlp.remove_pipe(name)"
      ],
      "metadata": {
        "id": "1odVYOVBtHFv"
      },
      "id": "1odVYOVBtHFv",
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a NEW entity_ruler with lowercased phrase matching and overwrite behavior\n",
        "ruler = nlp.add_pipe(\n",
        "    \"entity_ruler\",\n",
        "    before=\"ner\",\n",
        "    config={\"overwrite_ents\": True, \"phrase_matcher_attr\": \"LOWER\"}\n",
        ")"
      ],
      "metadata": {
        "id": "im9ANQWgtbgh"
      },
      "id": "im9ANQWgtbgh",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are adding our new labels:"
      ],
      "metadata": {
        "id": "KX1enNZOtf1U"
      },
      "id": "KX1enNZOtf1U"
    },
    {
      "cell_type": "code",
      "source": [
        "# Option one: Define precise patterns, here for platforms:\n",
        "platforms = [\"Tinder\", \"Reddit\", \"YouTube\", \"Instagram\", \"TikTok\", \"Twitter\", \"X\"]\n",
        "patterns = [{\"label\": \"PLATFORM\", \"pattern\": p} for p in platforms]"
      ],
      "metadata": {
        "id": "jV-TR8aAtzv6"
      },
      "id": "jV-TR8aAtzv6",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option two: Other custom entities\n",
        "patterns += [\n",
        "    {\"label\": \"PERSON\",   \"pattern\": \"Chad\"},\n",
        "    {\"label\": \"PERSON\",   \"pattern\": \"Stacy\"},\n",
        "    {\"label\": \"IDEOLOGY\", \"pattern\": \"Redpill\"},\n",
        "    {\"label\": \"IDEOLOGY\", \"pattern\": \"Blackpill\"},\n",
        "    {\"label\": \"COMMUNITY\",\"pattern\": \"normie\"},\n",
        "    {\"label\": \"SLUR\",     \"pattern\": \"foid\"}\n",
        "]"
      ],
      "metadata": {
        "id": "B_eN7anAt3Dp"
      },
      "id": "B_eN7anAt3Dp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We add the patterns\n",
        "ruler.add_patterns(patterns)"
      ],
      "metadata": {
        "id": "5ZKB0-R6t-CL"
      },
      "id": "5ZKB0-R6t-CL",
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the results:"
      ],
      "metadata": {
        "id": "EYOOyalRuBDT"
      },
      "id": "EYOOyalRuBDT"
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "a6402c0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6402c0e",
        "outputId": "cf57cb96-6173-4ed5-af32-8f7e7bdc22bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Frequent Named Entities (EntityRuler + NER):\n",
            "reddit (PLATFORM): 2\n",
            "today (DATE): 2\n",
            "NSFW (ORG): 2\n",
            "1000+ (DATE): 1\n",
            "a few day (DATE): 1\n",
            "12 hours (TIME): 1\n",
            "LDAR (NORP): 1\n",
            "Demetrious Johnson (PERSON): 1\n",
            "UFC (GPE): 1\n",
            "Trucels (GPE): 1\n",
            "three years (DATE): 1\n",
            "Hollywood (GPE): 1\n",
            "my freshman year (DATE): 1\n",
            "Norway (GPE): 1\n",
            "winters (DATE): 1\n",
            "and few hours (TIME): 1\n",
            "Beans (NORP): 1\n",
            "Chicken (PERSON): 1\n",
            "Blonde Stacy - 7/10+ PSL (ORG): 1\n",
            "Blonde Becky - 5/10+ PSL (PERSON): 1\n"
          ]
        }
      ],
      "source": [
        "# Count entities on your dataset\n",
        "exclude_labels = {\"CARDINAL\", \"ORDINAL\", \"WORK_OF_ART\", \"PERCENT\"}\n",
        "entity_counter = Counter()\n",
        "\n",
        "for doc in nlp.pipe(df[\"text\"], batch_size=50):\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ not in exclude_labels:\n",
        "            entity_counter[(ent.text, ent.label_)] += 1\n",
        "\n",
        "print(\"Most Frequent Named Entities (EntityRuler + NER):\")\n",
        "for (text, label), count in entity_counter.most_common(20):\n",
        "    print(f\"{text} ({label}): {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Excersise**: Choose a term you would like to add and run the the NER Matcher on our dataset! Use the code above to add your examples."
      ],
      "metadata": {
        "id": "Sw2nuC95uP37"
      },
      "id": "Sw2nuC95uP37"
    },
    {
      "cell_type": "markdown",
      "id": "01c72a81",
      "metadata": {
        "id": "01c72a81"
      },
      "source": [
        "## üìö **3. Additional Material: Training a Custom NER Model (Simple Demo)**\n",
        "\n",
        "So far, we‚Äôve used:\n",
        "- Pre-trained entities (PERSON, ORG, DATE, etc.)\n",
        "- Rule-based customization (Matcher, EntityRuler)\n",
        "\n",
        "Another option is to **train the model** to recognize new entity types.  \n",
        "This requires **annotated data** ‚Äî examples of text with entity spans labeled.\n",
        "\n",
        "‚ö†Ô∏è This is just a toy demo to show the mechanics. Real training needs more data and time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a6a16f0",
      "metadata": {
        "id": "2a6a16f0"
      },
      "source": [
        "### Train the model from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Understanding Model Training in spaCy**\n",
        "\n",
        "Before training our own **Named Entity Recognition (NER)** model, here are the key ideas to understand:\n",
        "\n",
        "\n",
        "\n",
        "##### **Key Concepts**\n",
        "\n",
        "| üè∑Ô∏è **Concept** | üí° **What it Means** | üéØ **Why it Matters** |\n",
        "|:----------------|:--------------------|:----------------------|\n",
        "| **Annotated data** | Training needs examples where entities are *already labeled* in text ‚Äî e.g. `\"Redpill\" ‚Üí IDEOLOGY`. | The model can only learn from what it sees.<br><br>More examples and variety = better generalization. |\n",
        "| **Empty model**<br/>`spacy.blank(\"en\")` | Creates a model with **no prior knowledge** ‚Äî a clean slate. | Ideal for demos or custom domains.<br><br>The model learns entirely from your data. |\n",
        "| **Pretrained model**<br/>`en_core_web_sm` | A model that already understands **general English** syntax and entities. | You can **fine-tune** it instead of training from scratch.<br><br>This saves time and requires less data. |\n",
        "| **Adding an NER component** | spaCy pipelines are sequences like:<br/>`tokenizer ‚Üí tagger ‚Üí parser ‚Üí NER`. | Adding an NER step lets the model detect and label entities (e.g., `PERSON`, `ORG`, or custom ones like `IDEOLOGY`). |\n",
        "| **Token alignment & BILUO tags** | spaCy internally converts entity spans into the **BILUO** format:<br>**B**egin, **I**nside, **L**ast, **U**nit, **O**utside. | Ensures that entity spans match token boundaries.<br><br>This alignment is **essential for error-free training**. |\n",
        "| **Epochs / iterations** | One ‚Äúepoch‚Äù = one **full pass** through the dataset. Training repeats over multiple epochs. | Each pass helps the model refine its understanding.<br><br>More epochs ‚Üí more learning (to a point). |\n",
        "| **Updating model weights** | After every batch, spaCy adjusts internal **weights** based on the difference between predictions and correct labels. | These updates make the model gradually improve.<br><br>Over many updates, accuracy and stability increase. |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QR7shG9X6uRl"
      },
      "id": "QR7shG9X6uRl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes**\n",
        "\n",
        "\n",
        "* This is a toy example. With only a few sentences, the model will overfit quickly; that‚Äôs fine for demonstration.\n",
        "* For deterministic terms (exact names), an EntityRuler is often a better choice. Use training for fuzzier/variable mentions."
      ],
      "metadata": {
        "id": "2XKEsY9c0mCC"
      },
      "id": "2XKEsY9c0mCC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start the training!"
      ],
      "metadata": {
        "id": "vdVrnUH-BddK"
      },
      "id": "vdVrnUH-BddK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a summary of what the following code does:\n",
        "\n",
        "\n",
        "1. **Build a tiny training set** for a Named Entity Recognition (NER) task using a helper function that ensures entity spans align correctly to tokens\n",
        "(this prevents \"misalignment\" errors during training)\n",
        "2. Create and **train** a completely blank English NER **model** from scratch on two custom labels: IDEOLOGY and PLATFORM\n",
        "3. **Evaluate** the trained model on a new test sentence to see if it learned to recognize similar patterns\n"
      ],
      "metadata": {
        "id": "MmYzDj6LBfhN"
      },
      "id": "MmYzDj6LBfhN"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries for text processing and model training\n",
        "import re\n",
        "import random\n",
        "import spacy\n",
        "from spacy.training import Example, offsets_to_biluo_tags"
      ],
      "metadata": {
        "id": "kZmdkd6gCDUK"
      },
      "id": "kZmdkd6gCDUK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a helper function to build token-aligned entity spans. The `make_example()` function ensures that entity spans (start and end positions) line up exactly with token boundaries. This is required by spaCy for training.\n",
        "\n",
        "If an entity span cuts through a token (e.g., due to punctuation or whitespace), it will raise a clear error so you can adjust the example."
      ],
      "metadata": {
        "id": "t_AxIixUCF20"
      },
      "id": "t_AxIixUCF20"
    },
    {
      "cell_type": "code",
      "source": [
        "def make_example(text, spans, nlp_for_tokenization=None):\n",
        "    \"\"\"\n",
        "    text: str -> the input sentence\n",
        "    spans: list of tuples -> [(substring, LABEL), ...]\n",
        "           e.g. [(\"Blackpill\", \"IDEOLOGY\")]\n",
        "    Finds the FIRST occurrence of each substring in `text`,\n",
        "    checks that it aligns to token boundaries, and returns\n",
        "    a tuple in the format spaCy expects: (text, {\"entities\": [(start, end, LABEL), ...]})\n",
        "    \"\"\"\n",
        "    nlp_tok = nlp_for_tokenization or spacy.blank(\"en\")\n",
        "    doc = nlp_tok.make_doc(text)\n",
        "    ents = []\n",
        "    for substr, label in spans:\n",
        "        m = re.search(re.escape(substr), text)\n",
        "        if not m:\n",
        "            raise ValueError(f\"Substring not found: {substr!r} in: {text!r}\")\n",
        "        start_char, end_char = m.start(), m.end()\n",
        "        if doc.char_span(start_char, end_char) is None:\n",
        "            # If this happens, the substring doesn‚Äôt match full tokens.\n",
        "            # You can fix this by adjusting the substring or the tokenizer.\n",
        "            tokens = [t.text for t in doc]\n",
        "            raise ValueError(\n",
        "                f\"Not token-aligned: {substr!r} -> ({start_char},{end_char}). \"\n",
        "                f\"Tokens: {tokens}\"\n",
        "            )\n",
        "        ents.append((start_char, end_char, label))\n",
        "    return (text, {\"entities\": ents})"
      ],
      "metadata": {
        "id": "5bkUVGPKCqCN"
      },
      "id": "5bkUVGPKCqCN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Build a tiny toy dataset"
      ],
      "metadata": {
        "id": "InBloeQICuts"
      },
      "id": "InBloeQICuts"
    },
    {
      "cell_type": "code",
      "source": [
        "# Each entry is created with make_example() to ensure safe alignment.\n",
        "# The data has two labels: \"IDEOLOGY\" (e.g., Blackpill, Redpill) and \"PLATFORM\" (e.g., Reddit, Tinder).\n",
        "\n",
        "TRAIN_DATA = [\n",
        "    make_example(\"He follows the Blackpill ideology.\", [(\"Blackpill\", \"IDEOLOGY\")]),\n",
        "    make_example(\"Redpill beliefs are common on these forums.\", [(\"Redpill\", \"IDEOLOGY\")]),\n",
        "    make_example(\"She spends time on Reddit.\", [(\"Reddit\", \"PLATFORM\")]),\n",
        "    make_example(\"They met through Tinder.\", [(\"Tinder\", \"PLATFORM\")]),\n",
        "    make_example(\"Many users argue about Blackpill ideas on Reddit.\",\n",
        "                 [(\"Blackpill\", \"IDEOLOGY\"), (\"Reddit\", \"PLATFORM\")]),\n",
        "    make_example(\"Tinder and Reddit are popular apps.\",\n",
        "                 [(\"Tinder\", \"PLATFORM\"), (\"Reddit\", \"PLATFORM\")]),\n",
        "]\n",
        "\n",
        "\n",
        "# Optional: quick sanity check for alignment\n",
        "# -----------------------------------------------------\n",
        "# The function below visualizes tokenization and entity alignment\n",
        "# by converting entities into the BILUO tagging scheme.\n",
        "# BILUO = Begin, Inside, Last, Unit, Outside\n",
        "# Misaligned entities will appear as '-' in the sequence.\n",
        "\n",
        "def check_alignment(text, ents):\n",
        "    doc = spacy.blank(\"en\").make_doc(text)\n",
        "    print(text)\n",
        "    print(\"TOKENS:\", [t.text for t in doc])\n",
        "    print(\"BILUO:\", offsets_to_biluo_tags(doc, ents), \"\\n\")\n",
        "\n",
        "for text, ann in TRAIN_DATA:\n",
        "    check_alignment(text, ann[\"entities\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsn3nb2bC7X_",
        "outputId": "5042cf15-6c4e-4084-a81f-2e05c7264695"
      },
      "id": "wsn3nb2bC7X_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He follows the Blackpill ideology.\n",
            "TOKENS: ['He', 'follows', 'the', 'Blackpill', 'ideology', '.']\n",
            "BILUO: ['O', 'O', 'O', 'U-IDEOLOGY', 'O', 'O'] \n",
            "\n",
            "Redpill beliefs are common on these forums.\n",
            "TOKENS: ['Redpill', 'beliefs', 'are', 'common', 'on', 'these', 'forums', '.']\n",
            "BILUO: ['U-IDEOLOGY', 'O', 'O', 'O', 'O', 'O', 'O', 'O'] \n",
            "\n",
            "She spends time on Reddit.\n",
            "TOKENS: ['She', 'spends', 'time', 'on', 'Reddit', '.']\n",
            "BILUO: ['O', 'O', 'O', 'O', 'U-PLATFORM', 'O'] \n",
            "\n",
            "They met through Tinder.\n",
            "TOKENS: ['They', 'met', 'through', 'Tinder', '.']\n",
            "BILUO: ['O', 'O', 'O', 'U-PLATFORM', 'O'] \n",
            "\n",
            "Many users argue about Blackpill ideas on Reddit.\n",
            "TOKENS: ['Many', 'users', 'argue', 'about', 'Blackpill', 'ideas', 'on', 'Reddit', '.']\n",
            "BILUO: ['O', 'O', 'O', 'O', 'U-IDEOLOGY', 'O', 'O', 'U-PLATFORM', 'O'] \n",
            "\n",
            "Tinder and Reddit are popular apps.\n",
            "TOKENS: ['Tinder', 'and', 'Reddit', 'are', 'popular', 'apps', '.']\n",
            "BILUO: ['U-PLATFORM', 'O', 'U-PLATFORM', 'O', 'O', 'O', 'O'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Create a blank NER pipeline"
      ],
      "metadata": {
        "id": "xFR_7v2cC9Lb"
      },
      "id": "xFR_7v2cC9Lb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Start from an empty English pipeline and add the NER component.\n",
        "# Register the custom labels so the model knows what to predict.\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "ner = nlp.add_pipe(\"ner\")\n",
        "ner.add_label(\"IDEOLOGY\")\n",
        "ner.add_label(\"PLATFORM\")\n",
        "\n",
        "# Initialize training parameters (weights and optimizer)\n",
        "optimizer = nlp.initialize()"
      ],
      "metadata": {
        "id": "FgvEBBq6DCvT"
      },
      "id": "FgvEBBq6DCvT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Train the model"
      ],
      "metadata": {
        "id": "7nkFeBZhDEjV"
      },
      "id": "7nkFeBZhDEjV"
    },
    {
      "cell_type": "code",
      "source": [
        "# For demonstration purposes, we train for a small number of iterations on a very small dataset.\n",
        "# This is NOT a realistic setup ‚Äî it‚Äôs just to showhow the model learns to recognize the two entity types.\n",
        "\n",
        "# Fix the random seed for reproducible results\n",
        "random.seed(42)\n",
        "\n",
        "# Number of training iterations (epochs)\n",
        "n_iter = 20\n",
        "\n",
        "for i in range(n_iter):\n",
        "    # Shuffle training examples each epoch\n",
        "    random.shuffle(TRAIN_DATA)\n",
        "    losses = {}\n",
        "\n",
        "    # Train on each text‚Äìannotation pair\n",
        "    for text, annotations in TRAIN_DATA:\n",
        "        doc = nlp.make_doc(text)\n",
        "        example = Example.from_dict(doc, annotations)\n",
        "        nlp.update([example], sgd=optimizer, losses=losses, drop=0.2)\n",
        "\n",
        "    # Show progress every 5 epochs\n",
        "    if i % 5 == 0:\n",
        "        print(f\"Iteration {i} | Losses: {losses}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELzKyX-ADe85",
        "outputId": "6a4336d2-8be0-41f2-eb42-d7fa30cb01a6"
      },
      "id": "ELzKyX-ADe85",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 | Losses: {'ner': np.float32(34.188534)}\n",
            "Iteration 5 | Losses: {'ner': np.float32(3.493084)}\n",
            "Iteration 10 | Losses: {'ner': np.float32(8.713895e-05)}\n",
            "Iteration 15 | Losses: {'ner': np.float32(1.6563934e-05)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Test the trained model"
      ],
      "metadata": {
        "id": "wkr5jvrIDgNF"
      },
      "id": "wkr5jvrIDgNF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Try the model on a new sentence that combines both entity types\n",
        "# to see if it generalizes beyond the training examples.\n",
        "\n",
        "test_text = \"People debate Redpill ideas on Reddit and meet on Tinder.\"\n",
        "doc = nlp(test_text)\n",
        "print(\"\\nTest text:\", test_text)\n",
        "print(\"Entities:\", [(ent.text, ent.label_) for ent in doc.ents])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjHrMekVzA1F",
        "outputId": "9c288892-aba4-47f2-efc2-806fb0d1a74a"
      },
      "id": "fjHrMekVzA1F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test text: People debate Redpill ideas on Reddit and meet on Tinder.\n",
            "Entities: [('People', 'IDEOLOGY'), ('Redpill', 'IDEOLOGY'), ('Reddit', 'PLATFORM'), ('Tinder', 'PLATFORM')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9c0d608",
      "metadata": {
        "id": "e9c0d608"
      },
      "source": [
        "## üéØ What We Learned\n",
        "\n",
        "- Pre-trained NER is a great *starting point*, but‚Ä¶\n",
        "- Social media / hate speech data has **slang and unique entities** that default models miss.\n",
        "- Rule-based methods (`Matcher`, `EntityRuler`) let us quickly adapt NER for research.\n",
        "- Combining **default + rules + fine-tuning** makes the strongest pipelines.\n",
        "\n",
        "For your projects: Think about which entities are most meaningful (people? platforms? ideologies?) and adapt NER accordingly.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö Further Resources: Named Entity Recognition (NER)\n",
        "\n",
        "If you‚Äôd like to explore Named Entity Recognition further ‚Äî especially in the context of customization, domain adaptation, or research use ‚Äî here are some carefully selected resources:\n"
      ],
      "metadata": {
        "id": "aHWVZI9LEdVa"
      },
      "id": "aHWVZI9LEdVa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß™ Tutorials and Beginner-Friendly Guides\n",
        "\n",
        "- **spaCy Course (Highly Recommended)**  \n",
        "  https://course.spacy.io  \n",
        "  Interactive tutorials on NER, rule-based matching, and building pipelines.\n",
        "\n",
        "- **NLTK Book ‚Äì Chapter 7: Information Extraction**  \n",
        "  https://www.nltk.org/book/ch07.html  \n",
        "  Classic introduction to NER using rule-based techniques."
      ],
      "metadata": {
        "id": "Y0KVZN9REkT1"
      },
      "id": "Y0KVZN9REkT1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß† Customizing and Training NER Models with spaCy\n",
        "\n",
        "- **spaCy NER Docs**  \n",
        "  https://spacy.io/usage/linguistic-features#named-entities  \n",
        "  Overview of how NER works in spaCy and how to access entity labels.\n",
        "\n",
        "- **spaCy Rule-Based Matching** (Matcher & EntityRuler)  \n",
        "  https://spacy.io/usage/rule-based-matching  \n",
        "  How to define token patterns and add custom entities.\n",
        "\n",
        "- **Training a Custom NER Model in spaCy**  \n",
        "  https://spacy.io/usage/training  \n",
        "  End-to-end guide to creating training data and training your own model.\n",
        "\n",
        "- **Using spaCy Projects for Training Pipelines**  \n",
        "  https://spacy.io/usage/projects  \n",
        "  Helps manage training configs, assets, and evaluation."
      ],
      "metadata": {
        "id": "Jnnq0Wu1EmNS"
      },
      "id": "Jnnq0Wu1EmNS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ü§ñ Alternative NER Frameworks\n",
        "\n",
        "- **Hugging Face Transformers (for Fine-Tuned NER Models)**  \n",
        "  https://huggingface.co/models?pipeline_tag=token-classification  \n",
        "  Browse pre-trained NER models like `bert-base-cased-finetuned-conll03`.\n",
        "\n",
        "- **Tutorial: Fine-Tuning BERT for NER (Hugging Face)**  \n",
        "  https://huggingface.co/transformers/v4.6.1/custom_datasets.html#named-entity-recognition  \n",
        "  Advanced tutorial using PyTorch and Hugging Face datasets."
      ],
      "metadata": {
        "id": "V9J9H27YEtcm"
      },
      "id": "V9J9H27YEtcm"
    },
    {
      "cell_type": "markdown",
      "id": "be81eb17",
      "metadata": {
        "id": "be81eb17"
      },
      "source": [
        "\n",
        "### üìÑ (Some) Key Papers and Benchmarks\n",
        "\n",
        "\n",
        "- **Tjong Kim Sang & De Meulder (2003)**  \n",
        "  [Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition](https://aclanthology.org/W03-0419/)  \n",
        "  *Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003*.\n",
        "\n",
        "- **Nadeau & Sekine (2007)**  \n",
        "  [A Survey of Named Entity Recognition and Classification](https://www.jbe-platform.com/content/journals/10.1075/li.30.1.03nad)  \n",
        "  *Lingvisticae Investigationes, 30(1), 3-26*\n",
        "\n",
        "- **Li et al. (2022)**  \n",
        "  [A Survey on Deep Learning for Named Entity Recognition](https://ieeexplore.ieee.org/abstract/document/9039685)  \n",
        "  *IEEE Transactions on Knowledge and Data Engineering, 2021*\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}